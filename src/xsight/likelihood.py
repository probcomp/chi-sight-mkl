# AUTOGENERATED! DO NOT EDIT! File to edit: ../../notebooks/11 - Constrained Likelihood.ipynb.

# %% auto 0
__all__ = ['console', 'key', 'tfd', 'uniform', 'truncnormal', 'normal', 'diagnormal', 'mixture_of_diagnormals',
           'mixture_of_normals', 'mixture_of_truncnormals', 'normal_logpdf', 'truncnorm_logpdf', 'truncnorm_pdf', 'min',
           'max', 'outlier_uniform', 'get_1d_mixture_components', 'dslice', 'pad', 'mix_std',
           'make_constrained_sensor_model', 'get_data_logprobs', 'OutlierUniform', 'make_baseline_sensor_model']

# %% ../../notebooks/11 - Constrained Likelihood.ipynb 3
import jax
import jax.numpy as jnp
from jax import (jit, vmap)
import genjax
from genjax import gen, choice_map, vector_choice_map
import matplotlib.pyplot as plt
import numpy as np
import bayes3d
from .utils import *

console = genjax.pretty(show_locals=False)
key     = jax.random.PRNGKey(0)

# %% ../../notebooks/11 - Constrained Likelihood.ipynb 4
import genjax._src.generative_functions.distributions.tensorflow_probability as gentfp
import tensorflow_probability.substrates.jax as tfp
tfd = tfp.distributions

uniform = genjax.tfp_uniform

truncnormal = gentfp.TFPDistribution(
    lambda mu, sig, low, high: tfd.TruncatedNormal(mu, sig, low, high));

normal = gentfp.TFPDistribution(
    lambda mu, sig: tfd.Normal(mu, sig));

diagnormal = gentfp.TFPDistribution(
    lambda mus, sigs: tfd.MultivariateNormalDiag(mus, sigs));


mixture_of_diagnormals = gentfp.TFPDistribution(
    lambda ws, mus, sig: tfd.MixtureSameFamily(
        tfd.Categorical(ws),
        tfd.MultivariateNormalDiag(mus, sig * jnp.ones_like(mus))))

mixture_of_normals = gentfp.TFPDistribution(
    lambda ws, mus, sig: tfd.MixtureSameFamily(
        tfd.Categorical(ws),
        tfd.Normal(mus, sig * jnp.ones_like(mus))))


mixture_of_truncnormals = gentfp.TFPDistribution(
    lambda ws, mus, sigs, lows, highs: tfd.MixtureSameFamily(
        tfd.Categorical(ws),
        tfd.TruncatedNormal(mus, sigs, lows, highs)))

# %% ../../notebooks/11 - Constrained Likelihood.ipynb 5
from scipy.stats import truncnorm as scipy_truncnormal

normal_logpdf    = jax.scipy.stats.norm.logpdf
truncnorm_logpdf = jax.scipy.stats.truncnorm.logpdf
truncnorm_pdf    = jax.scipy.stats.truncnorm.pdf


# %% ../../notebooks/11 - Constrained Likelihood.ipynb 8
def get_1d_mixture_components(x, ys, sig):
    """Returns 1d mixture components and thier unnormalized weights."""
    # 1D-Mixture components and value to evaluate.
    # These are given by the distances ALONG ray through `x`
    d  = jnp.linalg.norm(x, axis=-1)
    ds = ys @ x / d
    
    # 1D-Mixture weights.
    # First compute the distances TO ray through `x`
    # and then transforming them appropriately.
    ws_ = jnp.linalg.norm(ds[...,None] * x/d - ys, axis=-1)
    ws  = normal_logpdf(ws_, loc=0.0, scale=sig) + normal_logpdf(0.0, loc=0.0, scale=sig)

    return d, ds, ws

# %% ../../notebooks/11 - Constrained Likelihood.ipynb 17
# Some helper to keep code concise
min = jnp.minimum
max = jnp.maximum


def dslice(X, i, j, w):     
    m = 2*w + 1
    return  jax.lax.dynamic_slice(X, (i, j, 0), (m, m, 3))   


def pad(X, w, val=-100.0):
    return jax.lax.pad(X,  val, ((w,w,0),(w,w,0),(0,0,0)))


def mix_std(ps, mus, stds):
    """Standard Deviation of a mixture of Gaussians."""
    return jnp.sqrt(jnp.sum(ps*stds**2) + jnp.sum(ps*mus**2) - (jnp.sum(ps*mus))**2)

# %% ../../notebooks/11 - Constrained Likelihood.ipynb 18
# TODO: The input Y should be an array only containing range measruements as well. 
#       For this to work we need to have the pixel vectors (the rays through each pixel)

def make_constrained_sensor_model(zmax, w):
    """Returns an (untruncated) constrained sensor model marginalized over outliers."""    

    pad_val = -100.0

    @genjax.drop_arguments
    @gen
    def _sensor_model_ij(i, j, Y_, sig, outlier):

        # Note that `i,j` are at the edge of the filter window,
        # the Center is offset by `w``
        y  = Y_[i+w,j+w] 
        ys = dslice(Y_, i, j, w).reshape(-1,3)
        
        d, ds, ws = get_1d_mixture_components(y, ys, sig)

        inlier_outlier_mix = genjax.tfp_mixture(genjax.tfp_categorical, [
                                mixture_of_normals, genjax.tfp_uniform])

        # Adjustment weights to make up for 
        # the difference to the 3dp3 model
        adj = logsumexp(ws) - jnp.log(len(ws))

        # zmax_ = d/y[2]*zmax
        zmax_ = zmax

        
        z = inlier_outlier_mix([jnp.log(1.0-outlier), jnp.log(outlier)], (
                                    (ws, ds, sig), 
                                    (0.0, zmax_))) @ "measurement"

        return z * y/d, adj

        
    @gen
    def sensor_model(Y, sig, outlier):   
        """Constrained sensor model."""
        Y_ = pad(Y, w, val=pad_val)

        I, J = jnp.mgrid[:Y.shape[0], :Y.shape[1]]
        I, J = I.ravel(), J.ravel()
                
        
        X, W = genjax.Map(_sensor_model_ij, (0,0,None,None,None))(I, J, Y_, sig, outlier) @ "X"
        W = W.reshape(Y.shape[:2])
        X = X.reshape(Y.shape)

        return X, W

    return sensor_model

# %% ../../notebooks/11 - Constrained Likelihood.ipynb 19
def get_data_logprobs(tr):
    pixel_addr = lambda i: genjax.select({"X":
        genjax.index_select(i,  genjax.select("measurement"))
    })
    inds = jnp.arange(tr["X", "measurement"].shape[0])
    logps = vmap(lambda i: tr.project(pixel_addr(i)))(inds)
    return logps

# %% ../../notebooks/11 - Constrained Likelihood.ipynb 21
from genjax.generative_functions.distributions import ExactDensity
from bayes3d.likelihood import threedp3_likelihood
from .mixtures import HeterogeneousMixture

# def make_baseline(zmax, w): 
    # return lambda X, Y, sig, outlier: threedp3_likelihood(X, Y, sig**2, outlier, zmax, w)

# %% ../../notebooks/11 - Constrained Likelihood.ipynb 22
from genjax.generative_functions.distributions import ExactDensity

class OutlierUniform(ExactDensity):
    def sample(self, key, y, zmax):
        u = zmax*jax.random.uniform(key)
        return u*y

    def logpdf(self, x, y, zmax):
        y_ = y/jnp.linalg.norm(y)
        u = jnp.dot(x,y_)
        return genjax.tfp_uniform.logpdf(u, 0.0, zmax)

outlier_uniform = OutlierUniform()


# %% ../../notebooks/11 - Constrained Likelihood.ipynb 23
# TODO: The input Y should be an array only containing range measruements as well. 
#       For this to work we need to have the pixel vectors (the rays through each pixel)

def make_baseline_sensor_model(zmax, w):
    """Explicit version of the 3dp3 sensor model."""
  
    pad_val = -100.0

    @genjax.drop_arguments
    @gen
    def _sensor_model_ij(i, j, Y_, sig, outlier):

        # Note that `i,j` are at the edge of the filter window,
        # the Center is offset by `w``
        y  = Y_[i+w,j+w] 
        ys = dslice(Y_, i, j, w).reshape(-1,3)

        m = len(ys)

        inlier_outlier_mix = HeterogeneousMixture([mixture_of_diagnormals, outlier_uniform])

        # zmax_ = d/y[2]*zmax
        zmax_ = zmax

        x = inlier_outlier_mix(jnp.array([1.0-outlier, outlier]), (
                                    (jnp.zeros(m), ys, sig), 
                                    (y, zmax_))) @ "measurement"

        return x, None

        
    @gen
    def sensor_model(Y, sig, outlier):   
        """Constrained sensor model."""
        Y_ = pad(Y, w, val=pad_val)

        I, J = jnp.mgrid[:Y.shape[0], :Y.shape[1]]
        I, J = I.ravel(), J.ravel()
                
        
        X,_ = genjax.Map(_sensor_model_ij, (0,0,None,None,None))(I, J, Y_, sig, outlier) @ "X"
        X = X.reshape(Y.shape)

        return X,None

    return sensor_model
